# Installation

The installation of DeepFlame is simple and requires [OpenFOAM-7], [LibCantera] and [LibTorch] .


## Install OpenFOAM-7
If [OpenFOAM-7] is not installed yet, please follow the instruction given on the official website. After installation, source your OpenFOAM via the default path below (or your own path for OpenFOAM bashrc).
```bash
source $HOME/OpenFOAM/OpenFOAM-7/etc/bashrc 
```

## Install [LibCantera] via [conda]
Use the commands below to install and activate LibCantera.
```bash
conda create -n libcantera

conda activate libcantera

conda install -c conda-forge boost fmt libcantera-devel
```
Note: Check your Miniconda3/envs/libcantera directory and make sure the install was successful (lib/ include/ etc. exist).

## Clone the [DeepFlame] repository
Clone the repository to your own device.
```bash
git clone https://github.com/deepmodeling/deepflame-dev.git

cd deepflame-dev
```



## Install precompiled [LibTorch]
```bash
wget https://download.pytorch.org/libtorch/cpu/libtorch-cxx11-abi-shared-with-deps-1.11.0%2Bcpu.zip

unzip libtorch-cxx11-abi-shared-with-deps-1.11.0+cpu.zip -d thirdParty

```

## Install DeepFlame
```bash
. install.sh
```
Note: Some compiling issues may happen due to system compatability. Instead of using conda installed Cantera C++ lib and the downloaded Torch C++ lib, try to compile your own Cantera and Torch C++ libraries.